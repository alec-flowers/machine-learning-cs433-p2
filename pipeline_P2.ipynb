{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Deep Knockoffs for Functional Magnetic Resonance Imaging to Generate Surrogate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the pipeline to follow to build Knockoffs from fMRI images. These knockoffs generate surrogate data that is used in non-parametric tests to obtain a Statistical Parametric Map (SPM) of the brain.\n",
    "\n",
    "First of all, some things to consider:\n",
    "* fMRI images have been obtained from the Brain Connectome Project and previously preprocessed. \n",
    "* \n",
    "\n",
    "## Structure\n",
    "The process is divided into 3 main parts, which consist of:\n",
    "1. Performing the **General Linear Model (GLM)** on the data: this is the classical method to obtain the SPM, which returns the fitted beta values for $$ y = X\\beta$$ where y is the fMRI timecourse and X is the design matrix of the experiment.\n",
    "\n",
    "\n",
    "2. **Generating Knockoffs**: given the data, the algorithm will build a machine to generate surrogate timecourses.\n",
    "    There are three methods:\n",
    "    * Gaussian Knockoffs\n",
    "    * Low Rank Knockoffs\n",
    "    * Deep Knockoffs\n",
    "    \n",
    "    \n",
    "3. Performing **Non-Parametric Tests**: the GLM is applied to the generated surrogate data to get the beta values and these are used to threshold the true betas using Non-Parametric Tests, which can be:\n",
    "    * Uncorrected Non-Parametric Test\n",
    "    * Corrected Non-Parametric Test\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== \n",
      " MOTOR \n",
      "==============================\n",
      "Loading data for task MOTOR...\n",
      "Loaded Data - Shape: (100, 379, 284)\n",
      "Loaded Task Paradigms - Shape: (100, 284)\n",
      "Computing GLM for task MOTOR...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task MOTOR...\n",
      "============================== \n",
      " GAMBLING \n",
      "==============================\n",
      "Loading data for task GAMBLING...\n",
      "Loaded Data - Shape: (100, 379, 253)\n",
      "Loaded Task Paradigms - Shape: (100, 253)\n",
      "Computing GLM for task GAMBLING...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task GAMBLING...\n",
      "============================== \n",
      " RELATIONAL \n",
      "==============================\n",
      "Loading data for task RELATIONAL...\n",
      "Loaded Data - Shape: (100, 379, 232)\n",
      "Loaded Task Paradigms - Shape: (100, 232)\n",
      "Computing GLM for task RELATIONAL...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task RELATIONAL...\n",
      "============================== \n",
      " SOCIAL \n",
      "==============================\n",
      "Loading data for task SOCIAL...\n",
      "Loaded Data - Shape: (100, 379, 274)\n",
      "Loaded Task Paradigms - Shape: (100, 274)\n",
      "Computing GLM for task SOCIAL...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task SOCIAL...\n",
      "============================== \n",
      " WM \n",
      "==============================\n",
      "Loading data for task WM...\n",
      "Loaded Data - Shape: (100, 379, 405)\n",
      "Loaded Task Paradigms - Shape: (100, 405)\n",
      "Computing GLM for task WM...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task WM...\n",
      "============================== \n",
      " EMOTION \n",
      "==============================\n",
      "Loading data for task EMOTION...\n",
      "Loaded Data - Shape: (100, 379, 176)\n",
      "Loaded Task Paradigms - Shape: (100, 186)\n",
      "Computing GLM for task EMOTION...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task EMOTION...\n",
      "============================== \n",
      " LANGUAGE \n",
      "==============================\n",
      "Loading data for task LANGUAGE...\n",
      "Loaded Data - Shape: (100, 379, 316)\n",
      "Loaded Task Paradigms - Shape: (100, 316)\n",
      "Computing GLM for task LANGUAGE...\n",
      "Separating conditions...\n",
      "Done!\n",
      "Convolving...\n",
      "Done!\n",
      "Fitting GLM for 100 subjects and 379 regions...\n",
      "Done!\n",
      "Saving activations and beta values for task LANGUAGE...\n"
     ]
    }
   ],
   "source": [
    "from implementation import glm\n",
    "glm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Knockoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'MOTOR'\n",
    "subject = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Gaussian Knockoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = knockoff_class.GaussianKnockOff(task, subject)  \n",
    "\n",
    "# Pre-processing the data: clustering to avoid correlations\n",
    "gaussian.pre_process(max_corr=.3)\n",
    "\n",
    "\n",
    "gaussian.fit() #trains a machine to build knockoffs\n",
    "# d.load_machine()  # gets the machine that will build knockoffs (if I fitted before) (only for Deep)\n",
    "# d.diagnostics()  \n",
    "# data_deep = d.transform()  #creates knockoffs for a specific subject, will create 101xregions\n",
    "# ko_betas = d.statistic(data_deep, save=True)  #runs glm\n",
    "# uncorrected_betas, corrected_betas = d.threshold(ko_betas, save=True)  #threshold with nonparametrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
